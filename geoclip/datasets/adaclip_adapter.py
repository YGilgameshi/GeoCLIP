"""
GeoCLIP - AdaCLIPæ•°æ®é›†é€‚é…å™¨
å°†åŸæœ‰çš„2Dæ•°æ®é›†é€‚é…ä¸º3Dæ•°æ®é›†ï¼Œé€šè¿‡æ·±åº¦ä¼°è®¡ç”Ÿæˆä¼ª3Dæ•°æ®
"""

import torch
import torch.nn as nn
import numpy as np
import cv2
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import json
from tqdm import tqdm
from PIL import Image
import hashlib

# å¯¼å…¥AdaCLIPåŸæœ‰çš„æ•°æ®é›†åŸºç±»
try:
    from dataset.base_dataset import BaseDataset
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥BaseDatasetï¼Œè¯·ç¡®ä¿åœ¨AdaCLIPé¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œ")

from geoclip.models.depth_estimator import DepthEstimator
from geoclip.utils.transforms import GeoCLIPTransforms


class AdaCLIPToGeoCLIPAdapter:
    """
    AdaCLIPæ•°æ®é›†åˆ°GeoCLIPçš„é€‚é…å™¨
    ä¸ºåŸæœ‰2Dæ•°æ®é›†ç”Ÿæˆæ·±åº¦ä¿¡æ¯
    """

    def __init__(self,
                 depth_estimator: Optional[DepthEstimator] = None,
                 cache_depth: bool = True,
                 depth_cache_dir: str = "./depth_cache",
                 device: str = None):

        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

        # åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨
        if depth_estimator is None:
            print("åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨...")
            self.depth_estimator = DepthEstimator(
                model_type="DPT_Large",  # ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹åç§°
                device=self.device
            )
        else:
            self.depth_estimator = depth_estimator

        self.cache_depth = cache_depth
        self.depth_cache_dir = Path(depth_cache_dir)

        if self.cache_depth:
            self.depth_cache_dir.mkdir(exist_ok=True, parents=True)
            print(f"æ·±åº¦ç¼“å­˜ç›®å½•: {self.depth_cache_dir}")

        self.transforms = GeoCLIPTransforms()

        print(f"AdaCLIPæ•°æ®é›†é€‚é…å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ·±åº¦ç¼“å­˜: {'å¯ç”¨' if cache_depth else 'ç¦ç”¨'}")
        print(f"è¿è¡Œè®¾å¤‡: {self.device}")

    def get_depth_cache_path(self, image_path: str) -> str:
        """è·å–æ·±åº¦ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        # ä½¿ç”¨MD5 hashç”Ÿæˆç¨³å®šçš„ç¼“å­˜æ–‡ä»¶å
        path_str = str(image_path)
        path_hash = hashlib.md5(path_str.encode()).hexdigest()[:16]
        cache_filename = f"depth_{path_hash}.npy"
        return str(self.depth_cache_dir / cache_filename)

    def estimate_or_load_depth(self, image_path: str, image: np.ndarray = None) -> np.ndarray:
        """ä¼°è®¡æˆ–åŠ è½½ç¼“å­˜çš„æ·±åº¦å›¾"""
        cache_path = self.get_depth_cache_path(image_path)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if self.cache_depth and os.path.exists(cache_path):
            try:
                depth = np.load(cache_path)
                return depth.astype(np.float32)
            except Exception as e:
                print(f"åŠ è½½ç¼“å­˜å¤±è´¥ {cache_path}: {e}")

        # å¦‚æœæ²¡æœ‰æä¾›å›¾åƒï¼Œä»è·¯å¾„åŠ è½½
        if image is None:
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # ä¼°è®¡æ·±åº¦
        depth = self.estimate_depth(image)

        # ä¿å­˜åˆ°ç¼“å­˜
        if self.cache_depth:
            try:
                np.save(cache_path, depth)
            except Exception as e:
                print(f"ä¿å­˜ç¼“å­˜å¤±è´¥ {cache_path}: {e}")

        return depth

    def estimate_depth(self, image: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨æ·±åº¦ä¼°è®¡å™¨ä¼°è®¡æ·±åº¦"""
        try:
            # é¢„å¤„ç†å›¾åƒ
            if len(image.shape) == 3:
                # RGBå›¾åƒ
                if image.dtype == np.uint8:
                    image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
                else:
                    image_tensor = torch.from_numpy(image).permute(2, 0, 1).float()
            else:
                # ç°åº¦å›¾åƒ
                if image.dtype == np.uint8:
                    image_tensor = torch.from_numpy(image).float() / 255.0
                else:
                    image_tensor = torch.from_numpy(image).float()

                # æ‰©å±•åˆ°3é€šé“
                if len(image_tensor.shape) == 2:
                    image_tensor = image_tensor.unsqueeze(0).repeat(3, 1, 1)

            # æ·»åŠ batchç»´åº¦
            image_tensor = image_tensor.unsqueeze(0)
            image_tensor = image_tensor.to(self.device)

            # æ·±åº¦ä¼°è®¡
            with torch.no_grad():
                depth_tensor = self.depth_estimator(image_tensor)

            # è½¬æ¢å›numpy
            if depth_tensor.dim() == 4:
                depth = depth_tensor[0, 0].cpu().numpy()  # [H, W]
            elif depth_tensor.dim() == 3:
                depth = depth_tensor[0].cpu().numpy()
            else:
                depth = depth_tensor.cpu().numpy()

            return depth.astype(np.float32)

        except Exception as e:
            print(f"æ·±åº¦ä¼°è®¡å¤±è´¥: {e}")
            # è¿”å›é›¶æ·±åº¦å›¾ä½œä¸ºfallback
            h, w = image.shape[:2]
            return np.zeros((h, w), dtype=np.float32)

    def preprocess_dataset(self, dataset_class, dataset_config: Dict[str, Any]) -> Dict[str, int]:
        """
        é¢„å¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼Œç”Ÿæˆæ‰€æœ‰æ·±åº¦å›¾

        Args:
            dataset_class: æ•°æ®é›†ç±»
            dataset_config: æ•°æ®é›†é…ç½®å‚æ•°

        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """

        print(f"å¼€å§‹é¢„å¤„ç†æ•°æ®é›†: {dataset_config.get('name', 'Unknown')}")

        stats = {
            'total_processed': 0,
            'cache_hits': 0,
            'new_estimates': 0,
            'errors': 0
        }

        # å¤„ç†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        for training in [True, False]:
            phase = 'train' if training else 'test'
            print(f"å¤„ç† {phase} æ•°æ®...")

            try:
                # åˆ›å»ºæ•°æ®é›†å®ä¾‹ï¼ˆä½¿ç”¨æ’ç­‰å˜æ¢é¿å…å¤æ‚å¤„ç†ï¼‰
                config = dataset_config.copy()
                config['training'] = training
                config['transform'] = lambda x: x
                config['target_transform'] = lambda x: x

                dataset = dataset_class(**config)

                # éå†æ•°æ®é›†
                for idx in tqdm(range(len(dataset)), desc=f"Processing {phase}"):
                    try:
                        # è·å–æ ·æœ¬ä¿¡æ¯ï¼ˆä½†ä¸å®é™…åŠ è½½æ•°æ®ï¼‰
                        data_info = dataset.data_all[idx]
                        img_path = data_info['img_path']
                        full_path = os.path.join(dataset.root, img_path)

                        # æ£€æŸ¥ç¼“å­˜
                        cache_path = self.get_depth_cache_path(full_path)
                        if os.path.exists(cache_path):
                            stats['cache_hits'] += 1
                        else:
                            # ä¼°è®¡æ·±åº¦ï¼ˆä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
                            _ = self.estimate_or_load_depth(full_path)
                            stats['new_estimates'] += 1

                        stats['total_processed'] += 1

                    except Exception as e:
                        print(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                        stats['errors'] += 1

            except Exception as e:
                print(f"åˆ›å»º {phase} æ•°æ®é›†æ—¶å‡ºé”™: {e}")

        print(f"æ•°æ®é›†é¢„å¤„ç†å®Œæˆ:")
        print(f"  æ€»å¤„ç†: {stats['total_processed']}")
        print(f"  ç¼“å­˜å‘½ä¸­: {stats['cache_hits']}")
        print(f"  æ–°ä¼°è®¡: {stats['new_estimates']}")
        print(f"  é”™è¯¯: {stats['errors']}")

        return stats


class GeoCLIP_AdaCLIPDataset(BaseDataset):
    """
    GeoCLIPç‰ˆæœ¬çš„AdaCLIPæ•°æ®é›†
    åœ¨åŸæœ‰æ•°æ®é›†åŸºç¡€ä¸Šæ·»åŠ æ·±åº¦ä¿¡æ¯
    """

    def __init__(self,
                 dataset_name: str,
                 clsnames: List[str],
                 transform,
                 target_transform,
                 root: str,
                 aug_rate: float = 0.0,
                 training: bool = True,
                 depth_adapter: Optional[AdaCLIPToGeoCLIPAdapter] = None,
                 depth_transform=None):

        self.dataset_name = dataset_name
        self.depth_adapter = depth_adapter or AdaCLIPToGeoCLIPAdapter()
        self.depth_transform = depth_transform

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            clsnames=clsnames,
            transform=transform,
            target_transform=target_transform,
            root=root,
            aug_rate=aug_rate,
            training=training
        )

        print(f"GeoCLIP-{dataset_name} æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ")
        print(f"  æ ·æœ¬æ•°é‡: {len(self.data_all)}")
        print(f"  ç±»åˆ«æ•°é‡: {len(self.cls_names)}")

    def __getitem__(self, index):
        """é‡å†™getitemæ–¹æ³•ï¼Œæ·»åŠ æ·±åº¦ä¿¡æ¯"""
        # è·å–åŸæœ‰æ•°æ®
        original_sample = super().__getitem__(index)

        # æ·»åŠ æ·±åº¦ä¿¡æ¯
        img_path = self.data_all[index]['img_path']
        full_img_path = os.path.join(self.root, img_path)

        try:
            # ä¼°è®¡æˆ–åŠ è½½æ·±åº¦
            depth = self.depth_adapter.estimate_or_load_depth(full_img_path)

            # åº”ç”¨æ·±åº¦å˜æ¢
            if self.depth_transform is not None:
                # å½’ä¸€åŒ–æ·±åº¦å›¾åˆ°[0, 1]èŒƒå›´
                depth_min, depth_max = depth.min(), depth.max()
                if depth_max > depth_min:
                    depth_normalized = (depth - depth_min) / (depth_max - depth_min)
                else:
                    depth_normalized = np.zeros_like(depth)

                # è½¬æ¢ä¸ºPIL Image
                depth_pil = Image.fromarray((depth_normalized * 255).astype(np.uint8), mode='L')
                depth_transformed = self.depth_transform(depth_pil)

                # å¦‚æœæ˜¯tensorï¼Œè½¬æ¢å›åŸå§‹æ·±åº¦å€¼èŒƒå›´
                if isinstance(depth_transformed, torch.Tensor):
                    if depth_max > depth_min:
                        depth_final = depth_transformed.float() * (depth_max - depth_min) + depth_min
                    else:
                        depth_final = depth_transformed.float()
                else:
                    depth_final = np.array(depth_transformed, dtype=np.float32)
                    if depth_max > depth_min:
                        depth_final = depth_final * (depth_max - depth_min) + depth_min

            else:
                # ç›´æ¥è½¬æ¢ä¸ºtensor
                depth_final = torch.from_numpy(depth).float()
                if depth_final.dim() == 2:
                    depth_final = depth_final.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦

            # æ·»åŠ åˆ°æ ·æœ¬ä¸­
            original_sample['depth'] = depth_final
            original_sample['has_depth'] = True
            original_sample['depth_range'] = (depth.min().item(), depth.max().item())

        except Exception as e:
            print(f"ä¸ºæ ·æœ¬ {index} ç”Ÿæˆæ·±åº¦å›¾æ—¶å‡ºé”™: {e}")
            # åˆ›å»ºé›¶æ·±åº¦å›¾ä½œä¸ºfallback
            if hasattr(original_sample['img'], 'shape'):
                h, w = original_sample['img'].shape[-2:]
                original_sample['depth'] = torch.zeros(1, h, w, dtype=torch.float32)
            else:
                original_sample['depth'] = torch.zeros(1, 256, 256, dtype=torch.float32)
            original_sample['has_depth'] = False
            original_sample['depth_range'] = (0.0, 0.0)

        return original_sample


# ä¾¿åˆ©çš„å·¥å‚å‡½æ•°
def create_geoclip_dataset(dataset_name: str,
                           clsnames: List[str] = None,
                           transform=None,
                           target_transform=None,
                           depth_transform=None,
                           root: str = None,
                           training: bool = True,
                           preprocess_all: bool = False,
                           cache_depth: bool = True,
                           depth_cache_dir: str = None,
                           **kwargs) -> GeoCLIP_AdaCLIPDataset:
    """
    åˆ›å»ºGeoCLIPç‰ˆæœ¬çš„AdaCLIPæ•°æ®é›†

    Args:
        dataset_name: æ•°æ®é›†åç§° ('mvtec', 'visa', 'colondb', ç­‰)
        clsnames: ç±»åˆ«åç§°åˆ—è¡¨
        transform: å›¾åƒå˜æ¢
        target_transform: ç›®æ ‡å˜æ¢
        depth_transform: æ·±åº¦å›¾å˜æ¢
        root: æ•°æ®é›†æ ¹ç›®å½•
        training: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
        preprocess_all: æ˜¯å¦é¢„å¤„ç†æ•´ä¸ªæ•°æ®é›†
        cache_depth: æ˜¯å¦ç¼“å­˜æ·±åº¦å›¾
        depth_cache_dir: æ·±åº¦ç¼“å­˜ç›®å½•
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        GeoCLIPæ•°æ®é›†å®ä¾‹
    """

    # å¯¼å…¥å¯¹åº”çš„æ•°æ®é›†ä¿¡æ¯
    dataset_class = None
    default_clsnames = None
    default_root = None

    if dataset_name == 'mvtec':
        try:
            from dataset.mvtec import MVTecDataset, MVTEC_CLS_NAMES, MVTEC_ROOT
            dataset_class = MVTecDataset
            default_clsnames = MVTEC_CLS_NAMES
            default_root = MVTEC_ROOT
        except ImportError:
            raise ImportError(f"æ— æ³•å¯¼å…¥{dataset_name}æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥å¯¼å…¥è·¯å¾„")

    elif dataset_name == 'visa':
        try:
            from dataset.visa import VisaDataset, VISA_CLS_NAMES, VISA_ROOT
            dataset_class = VisaDataset
            default_clsnames = VISA_CLS_NAMES
            default_root = VISA_ROOT
        except ImportError:
            raise ImportError(f"æ— æ³•å¯¼å…¥{dataset_name}æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥å¯¼å…¥è·¯å¾„")

    elif dataset_name == 'colondb':
        try:
            from dataset.colondb import ColonDBDataset, ColonDB_CLS_NAMES, ColonDB_ROOT
            dataset_class = ColonDBDataset
            default_clsnames = ColonDB_CLS_NAMES
            default_root = ColonDB_ROOT
        except ImportError:
            raise ImportError(f"æ— æ³•å¯¼å…¥{dataset_name}æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥å¯¼å…¥è·¯å¾„")

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}")

    # ä½¿ç”¨é»˜è®¤å€¼
    if clsnames is None:
        clsnames = default_clsnames
    if root is None:
        root = default_root
    if depth_cache_dir is None:
        depth_cache_dir = f"./depth_cache_{dataset_name}"

    # åˆ›å»ºé€‚é…å™¨
    adapter = AdaCLIPToGeoCLIPAdapter(
        cache_depth=cache_depth,
        depth_cache_dir=depth_cache_dir
    )

    # å¦‚æœéœ€è¦é¢„å¤„ç†æ•´ä¸ªæ•°æ®é›†
    if preprocess_all:
        print("å¼€å§‹é¢„å¤„ç†æ•°æ®é›†...")
        dataset_config = {
            'name': dataset_name,
            'clsnames': clsnames,
            'root': root,
            **kwargs
        }
        adapter.preprocess_dataset(dataset_class, dataset_config)

    # åˆ›å»ºæ•°æ®é›†
    dataset = GeoCLIP_AdaCLIPDataset(
        dataset_name=dataset_name,
        clsnames=clsnames,
        transform=transform,
        target_transform=target_transform,
        depth_transform=depth_transform,
        root=root,
        training=training,
        depth_adapter=adapter,
        **{k: v for k, v in kwargs.items()
           if k not in ['cache_depth', 'depth_cache_dir']}
    )

    return dataset


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
def test_adapter():
    """æµ‹è¯•é€‚é…å™¨åŠŸèƒ½"""
    print("=== æµ‹è¯•AdaCLIPæ•°æ®é›†é€‚é…å™¨ ===")

    try:
        # 1. æµ‹è¯•æ·±åº¦ä¼°è®¡é€‚é…å™¨
        print("\n1. æµ‹è¯•æ·±åº¦ä¼°è®¡é€‚é…å™¨")
        adapter = AdaCLIPToGeoCLIPAdapter(
            cache_depth=True,
            depth_cache_dir="./test_depth_cache"
        )

        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        test_path = "test_image.jpg"

        # æµ‹è¯•æ·±åº¦ä¼°è®¡
        depth = adapter.estimate_or_load_depth(test_path, test_image)
        print(f"âœ… æ·±åº¦ä¼°è®¡æˆåŠŸ:")
        print(f"   æ·±åº¦å½¢çŠ¶: {depth.shape}")
        print(f"   æ·±åº¦èŒƒå›´: {depth.min():.3f} - {depth.max():.3f}")

        # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
        depth2 = adapter.estimate_or_load_depth(test_path, test_image)
        cache_works = np.allclose(depth, depth2)
        print(f"âœ… ç¼“å­˜æµ‹è¯•: {'æˆåŠŸ' if cache_works else 'å¤±è´¥'}")

        # 2. æµ‹è¯•æ•°æ®é›†åˆ›å»ºï¼ˆå¯èƒ½éœ€è¦å®é™…æ•°æ®é›†ï¼‰
        print("\n2. æµ‹è¯•æ•°æ®é›†åˆ›å»º")
        try:
            import torchvision.transforms as transforms

            # ç®€å•çš„transform
            simple_transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor()
            ])

            depth_transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor()
            ])

            dataset = create_geoclip_dataset(
                dataset_name='mvtec',
                clsnames=['bottle'],  # åªæµ‹è¯•ä¸€ä¸ªç±»åˆ«
                transform=simple_transform,
                target_transform=simple_transform,
                depth_transform=depth_transform,
                training=True,
                preprocess_all=False,
                cache_depth=True
            )

            print(f"âœ… GeoCLIPæ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")

            # æµ‹è¯•è·å–æ ·æœ¬
            if len(dataset) > 0:
                sample = dataset[0]
                print(f"âœ… æ ·æœ¬é”®: {list(sample.keys())}")
                if 'depth' in sample:
                    print(f"   æ·±åº¦å½¢çŠ¶: {sample['depth'].shape}")
                    print(f"   æ˜¯å¦æœ‰æ·±åº¦: {sample['has_depth']}")
                    print(f"   æ·±åº¦èŒƒå›´: {sample.get('depth_range', 'N/A')}")

        except Exception as e:
            print(f"âš ï¸ æ•°æ®é›†æµ‹è¯•è·³è¿‡ (å¯èƒ½ç¼ºå°‘æ•°æ®): {e}")

        print("\nğŸ‰ é€‚é…å™¨æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_adapter()