"""
GeoCLIP - ç‰¹å¾èåˆæ¨¡å—
2D CLIPç‰¹å¾ä¸3Då‡ ä½•ç‰¹å¾èåˆç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Union, Any
import math


class FeatureFusionModule(nn.Module):
    """
    2D CLIPç‰¹å¾ä¸3Då‡ ä½•ç‰¹å¾èåˆæ¨¡å—
    """

    def __init__(self,
                 clip_dim: int = 512,
                 geometry_dim: int = 512,
                 fusion_dim: int = 1024,
                 output_dim: int = 512,
                 fusion_type: str = "cross_attention"):
        super(FeatureFusionModule, self).__init__()

        self.fusion_type = fusion_type
        self.clip_dim = clip_dim
        self.geometry_dim = geometry_dim
        self.fusion_dim = fusion_dim
        self.output_dim = output_dim

        if fusion_type == "cross_attention":
            self._build_cross_attention()
        elif fusion_type == "adaptive_fusion":
            self._build_adaptive_fusion()
        elif fusion_type == "simple_concat":
            self._build_simple_concat()
        elif fusion_type == "multihead_attention":
            self._build_multihead_attention()
        elif fusion_type == "gated_fusion":
            self._build_gated_fusion()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èåˆç±»å‹: {fusion_type}")

    def _build_cross_attention(self):
        """æ„å»ºäº¤å‰æ³¨æ„åŠ›èåˆ"""
        # æŠ•å½±åˆ°ç›¸åŒç»´åº¦
        self.clip_proj = nn.Linear(self.clip_dim, self.fusion_dim)
        self.geometry_proj = nn.Linear(self.geometry_dim, self.fusion_dim)

        # äº¤å‰æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=self.fusion_dim,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Sequential(
            nn.Linear(self.fusion_dim * 2, self.output_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(self.output_dim, self.output_dim)
        )

    def _build_adaptive_fusion(self):
        """æ„å»ºè‡ªé€‚åº”èåˆ"""
        # ç‰¹å¾æŠ•å½±
        self.clip_proj = nn.Linear(self.clip_dim, self.fusion_dim)
        self.geometry_proj = nn.Linear(self.geometry_dim, self.fusion_dim)

        # è‡ªé€‚åº”æƒé‡ç½‘ç»œ
        self.weight_net = nn.Sequential(
            nn.Linear(self.fusion_dim * 2, self.fusion_dim),
            nn.ReLU(inplace=True),
            nn.Linear(self.fusion_dim, 2),
            nn.Softmax(dim=-1)
        )

        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(self.fusion_dim, self.output_dim)

    def _build_simple_concat(self):
        """æ„å»ºç®€å•è¿æ¥èåˆ"""
        self.fusion_proj = nn.Sequential(
            nn.Linear(self.clip_dim + self.geometry_dim, self.fusion_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(self.fusion_dim, self.output_dim)
        )

    def _build_multihead_attention(self):
        """æ„å»ºå¤šå¤´æ³¨æ„åŠ›èåˆ"""
        # æŠ•å½±å±‚
        self.clip_proj = nn.Linear(self.clip_dim, self.fusion_dim)
        self.geometry_proj = nn.Linear(self.geometry_dim, self.fusion_dim)

        # å¤šå¤´è‡ªæ³¨æ„åŠ›
        self.self_attention = nn.MultiheadAttention(
            embed_dim=self.fusion_dim,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        # å‰é¦ˆç½‘ç»œ
        self.ffn = nn.Sequential(
            nn.Linear(self.fusion_dim, self.fusion_dim * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(self.fusion_dim * 2, self.output_dim)
        )

        # Layer Normalization
        self.layer_norm1 = nn.LayerNorm(self.fusion_dim)
        self.layer_norm2 = nn.LayerNorm(self.output_dim)

    def _build_gated_fusion(self):
        """æ„å»ºé—¨æ§èåˆ"""
        # ç‰¹å¾æŠ•å½±
        self.clip_proj = nn.Linear(self.clip_dim, self.fusion_dim)
        self.geometry_proj = nn.Linear(self.geometry_dim, self.fusion_dim)

        # é—¨æ§ç½‘ç»œ
        self.gate_clip = nn.Sequential(
            nn.Linear(self.fusion_dim, self.fusion_dim),
            nn.Sigmoid()
        )

        self.gate_geometry = nn.Sequential(
            nn.Linear(self.fusion_dim, self.fusion_dim),
            nn.Sigmoid()
        )

        # èåˆç½‘ç»œ
        self.fusion_net = nn.Sequential(
            nn.Linear(self.fusion_dim, self.fusion_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(self.fusion_dim, self.output_dim)
        )

    def forward(self, clip_features: torch.Tensor,
                geometry_features: torch.Tensor) -> torch.Tensor:
        """
        èåˆ2Då’Œ3Dç‰¹å¾

        Args:
            clip_features: CLIP 2Dç‰¹å¾ [B, clip_dim]
            geometry_features: å‡ ä½•3Dç‰¹å¾ [B, geometry_dim]

        Returns:
            fused_features: èåˆç‰¹å¾ [B, output_dim]
        """
        if self.fusion_type == "cross_attention":
            return self._cross_attention_forward(clip_features, geometry_features)
        elif self.fusion_type == "adaptive_fusion":
            return self._adaptive_fusion_forward(clip_features, geometry_features)
        elif self.fusion_type == "simple_concat":
            return self._simple_concat_forward(clip_features, geometry_features)
        elif self.fusion_type == "multihead_attention":
            return self._multihead_attention_forward(clip_features, geometry_features)
        elif self.fusion_type == "gated_fusion":
            return self._gated_fusion_forward(clip_features, geometry_features)

    def _cross_attention_forward(self, clip_feat, geometry_feat):
        """äº¤å‰æ³¨æ„åŠ›å‰å‘ä¼ æ’­"""
        # æŠ•å½±
        clip_proj = self.clip_proj(clip_feat).unsqueeze(1)  # [B, 1, fusion_dim]
        geometry_proj = self.geometry_proj(geometry_feat).unsqueeze(1)  # [B, 1, fusion_dim]

        # äº¤å‰æ³¨æ„åŠ›ï¼šCLIPæŸ¥è¯¢å‡ ä½•ç‰¹å¾
        clip_enhanced, _ = self.cross_attention(clip_proj, geometry_proj, geometry_proj)

        # äº¤å‰æ³¨æ„åŠ›ï¼šå‡ ä½•æŸ¥è¯¢CLIPç‰¹å¾
        geometry_enhanced, _ = self.cross_attention(geometry_proj, clip_proj, clip_proj)

        # è¿æ¥å’ŒæŠ•å½±
        fused = torch.cat([clip_enhanced.squeeze(1), geometry_enhanced.squeeze(1)], dim=1)
        return self.output_proj(fused)

    def _adaptive_fusion_forward(self, clip_feat, geometry_feat):
        """è‡ªé€‚åº”èåˆå‰å‘ä¼ æ’­"""
        # æŠ•å½±
        clip_proj = self.clip_proj(clip_feat)
        geometry_proj = self.geometry_proj(geometry_feat)

        # è®¡ç®—è‡ªé€‚åº”æƒé‡
        combined = torch.cat([clip_proj, geometry_proj], dim=1)
        weights = self.weight_net(combined)  # [B, 2]

        # åŠ æƒèåˆ
        w1, w2 = weights[:, 0:1], weights[:, 1:2]
        fused = w1 * clip_proj + w2 * geometry_proj

        return self.output_proj(fused)

    def _simple_concat_forward(self, clip_feat, geometry_feat):
        """ç®€å•è¿æ¥å‰å‘ä¼ æ’­"""
        # ç®€å•è¿æ¥
        concatenated = torch.cat([clip_feat, geometry_feat], dim=1)
        return self.fusion_proj(concatenated)

    def _multihead_attention_forward(self, clip_feat, geometry_feat):
        """å¤šå¤´æ³¨æ„åŠ›å‰å‘ä¼ æ’­"""
        # æŠ•å½±
        clip_proj = self.clip_proj(clip_feat).unsqueeze(1)  # [B, 1, fusion_dim]
        geometry_proj = self.geometry_proj(geometry_feat).unsqueeze(1)  # [B, 1, fusion_dim]

        # è¿æ¥ç‰¹å¾
        combined = torch.cat([clip_proj, geometry_proj], dim=1)  # [B, 2, fusion_dim]

        # è‡ªæ³¨æ„åŠ›
        attended, _ = self.self_attention(combined, combined, combined)
        attended = self.layer_norm1(attended + combined)  # æ®‹å·®è¿æ¥

        # å…¨å±€å¹³å‡æ± åŒ–
        pooled = attended.mean(dim=1)  # [B, fusion_dim]

        # å‰é¦ˆç½‘ç»œ
        output = self.ffn(pooled)
        output = self.layer_norm2(output)

        return output

    def _gated_fusion_forward(self, clip_feat, geometry_feat):
        """é—¨æ§èåˆå‰å‘ä¼ æ’­"""
        # æŠ•å½±
        clip_proj = self.clip_proj(clip_feat)
        geometry_proj = self.geometry_proj(geometry_feat)

        # è®¡ç®—é—¨æ§
        clip_gate = self.gate_clip(clip_proj)
        geometry_gate = self.gate_geometry(geometry_proj)

        # é—¨æ§èåˆ
        gated_clip = clip_gate * clip_proj
        gated_geometry = geometry_gate * geometry_proj

        # ç›¸åŠ å¹¶é€šè¿‡èåˆç½‘ç»œ
        fused = gated_clip + gated_geometry
        return self.fusion_net(fused)

    def get_fusion_info(self) -> Dict[str, Any]:
        """è·å–èåˆæ¨¡å—ä¿¡æ¯"""
        return {
            'fusion_type': self.fusion_type,
            'clip_dim': self.clip_dim,
            'geometry_dim': self.geometry_dim,
            'fusion_dim': self.fusion_dim,
            'output_dim': self.output_dim,
            'parameters': sum(p.numel() for p in self.parameters())
        }


class BilinearFusionModule(nn.Module):
    """
    åŒçº¿æ€§èåˆæ¨¡å—
    ä½¿ç”¨åŒçº¿æ€§å˜æ¢è¿›è¡Œç‰¹å¾èåˆ
    """

    def __init__(self,
                 clip_dim: int = 512,
                 geometry_dim: int = 512,
                 output_dim: int = 512,
                 use_dropout: bool = True):
        super(BilinearFusionModule, self).__init__()

        self.clip_dim = clip_dim
        self.geometry_dim = geometry_dim
        self.output_dim = output_dim

        # åŒçº¿æ€§å˜æ¢
        self.bilinear = nn.Bilinear(clip_dim, geometry_dim, output_dim)

        # å•ç‹¬çš„çº¿æ€§å˜æ¢
        self.clip_linear = nn.Linear(clip_dim, output_dim)
        self.geometry_linear = nn.Linear(geometry_dim, output_dim)

        # è¾“å‡ºå±‚
        self.output_proj = nn.Sequential(
            nn.ReLU(inplace=True),
            nn.Dropout(0.1) if use_dropout else nn.Identity(),
            nn.Linear(output_dim, output_dim)
        )

    def forward(self, clip_features: torch.Tensor,
                geometry_features: torch.Tensor) -> torch.Tensor:
        """
        åŒçº¿æ€§èåˆå‰å‘ä¼ æ’­

        Args:
            clip_features: CLIPç‰¹å¾ [B, clip_dim]
            geometry_features: å‡ ä½•ç‰¹å¾ [B, geometry_dim]

        Returns:
            fused_features: èåˆç‰¹å¾ [B, output_dim]
        """
        # åŒçº¿æ€§é¡¹
        bilinear_term = self.bilinear(clip_features, geometry_features)

        # çº¿æ€§é¡¹
        clip_term = self.clip_linear(clip_features)
        geometry_term = self.geometry_linear(geometry_features)

        # èåˆ
        fused = bilinear_term + clip_term + geometry_term

        return self.output_proj(fused)


class ResidualFusionModule(nn.Module):
    """
    æ®‹å·®èåˆæ¨¡å—
    ä½¿ç”¨æ®‹å·®è¿æ¥è¿›è¡Œç‰¹å¾èåˆ
    """

    def __init__(self,
                 clip_dim: int = 512,
                 geometry_dim: int = 512,
                 hidden_dim: int = 1024,
                 output_dim: int = 512,
                 num_layers: int = 3):
        super(ResidualFusionModule, self).__init__()

        # è¾“å…¥æŠ•å½±
        self.clip_proj = nn.Linear(clip_dim, hidden_dim)
        self.geometry_proj = nn.Linear(geometry_dim, hidden_dim)

        # æ®‹å·®å—
        self.residual_blocks = nn.ModuleList([
            self._make_residual_block(hidden_dim)
            for _ in range(num_layers)
        ])

        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(hidden_dim, output_dim)

    def _make_residual_block(self, dim: int) -> nn.Module:
        """åˆ›å»ºæ®‹å·®å—"""
        return nn.Sequential(
            nn.Linear(dim, dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(dim, dim)
        )

    def forward(self, clip_features: torch.Tensor,
                geometry_features: torch.Tensor) -> torch.Tensor:
        """
        æ®‹å·®èåˆå‰å‘ä¼ æ’­
        """
        # æŠ•å½±
        clip_proj = self.clip_proj(clip_features)
        geometry_proj = self.geometry_proj(geometry_features)

        # åˆå§‹èåˆ
        x = clip_proj + geometry_proj

        # æ®‹å·®å—
        for block in self.residual_blocks:
            residual = x
            x = block(x) + residual  # æ®‹å·®è¿æ¥

        # è¾“å‡ºæŠ•å½±
        return self.output_proj(x)


def create_fusion_module(config: Dict[str, Any]) -> nn.Module:
    """
    æ ¹æ®é…ç½®åˆ›å»ºèåˆæ¨¡å—

    Args:
        config: èåˆæ¨¡å—é…ç½®

    Returns:
        fusion_module: èåˆæ¨¡å—å®ä¾‹
    """
    fusion_type = config.get('type', 'cross_attention')

    if fusion_type in ['cross_attention', 'adaptive_fusion', 'simple_concat',
                       'multihead_attention', 'gated_fusion']:
        return FeatureFusionModule(
            clip_dim=config.get('clip_dim', 512),
            geometry_dim=config.get('geometry_dim', 512),
            fusion_dim=config.get('fusion_dim', 1024),
            output_dim=config.get('output_dim', 512),
            fusion_type=fusion_type
        )
    elif fusion_type == 'bilinear':
        return BilinearFusionModule(
            clip_dim=config.get('clip_dim', 512),
            geometry_dim=config.get('geometry_dim', 512),
            output_dim=config.get('output_dim', 512),
            use_dropout=config.get('use_dropout', True)
        )
    elif fusion_type == 'residual':
        return ResidualFusionModule(
            clip_dim=config.get('clip_dim', 512),
            geometry_dim=config.get('geometry_dim', 512),
            hidden_dim=config.get('hidden_dim', 1024),
            output_dim=config.get('output_dim', 512),
            num_layers=config.get('num_layers', 3)
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„èåˆç±»å‹: {fusion_type}")


# æµ‹è¯•å‡½æ•°
def test_fusion_modules():
    """æµ‹è¯•èåˆæ¨¡å—"""
    print("=== æµ‹è¯•ç‰¹å¾èåˆæ¨¡å— ===")

    try:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        batch_size = 4
        clip_dim = 512
        geometry_dim = 512

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        clip_features = torch.randn(batch_size, clip_dim, device=device)
        geometry_features = torch.randn(batch_size, geometry_dim, device=device)

        # æµ‹è¯•æ‰€æœ‰èåˆç±»å‹
        fusion_types = [
            'cross_attention', 'adaptive_fusion', 'simple_concat',
            'multihead_attention', 'gated_fusion', 'bilinear', 'residual'
        ]

        for fusion_type in fusion_types:
            print(f"\næµ‹è¯• {fusion_type} èåˆ:")

            config = {
                'type': fusion_type,
                'clip_dim': clip_dim,
                'geometry_dim': geometry_dim,
                'fusion_dim': 1024,
                'output_dim': 512
            }

            fusion_module = create_fusion_module(config).to(device)

            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                fused_features = fusion_module(clip_features, geometry_features)

            print(f"âœ… {fusion_type}: {clip_features.shape} + {geometry_features.shape} -> {fused_features.shape}")

            # è·å–æ¨¡å—ä¿¡æ¯
            if hasattr(fusion_module, 'get_fusion_info'):
                info = fusion_module.get_fusion_info()
                print(f"   å‚æ•°é‡: {info['parameters']:,}")

        print("\nğŸ‰ èåˆæ¨¡å—æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_fusion_modules()