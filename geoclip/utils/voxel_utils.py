"""
GeoCLIP - ä½“ç´ è½¬æ¢å·¥å…·
å°†2Dæ·±åº¦å›¾è½¬æ¢ä¸º3Dä½“ç´ è¡¨ç¤º
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Optional, Union, List, Dict
import cv2


def depth_to_pointcloud(depth: torch.Tensor,
                       intrinsics: Optional[torch.Tensor] = None,
                       max_depth: float = 10.0) -> List[torch.Tensor]:
    """
    å°†æ·±åº¦å›¾è½¬æ¢ä¸ºç‚¹äº‘

    Args:
        depth: æ·±åº¦å›¾ [B, 1, H, W]
        intrinsics: ç›¸æœºå†…å‚ [B, 3, 3] (å¯é€‰)
        max_depth: æœ€å¤§æ·±åº¦å€¼

    Returns:
        pointcloud: ç‚¹äº‘åˆ—è¡¨ [B x [N_i, 3]]
    """
    B, C, H, W = depth.shape
    device = depth.device

    # åˆ›å»ºåƒç´ åæ ‡ç½‘æ ¼
    u, v = torch.meshgrid(torch.arange(W, device=device, dtype=torch.float32),
                         torch.arange(H, device=device, dtype=torch.float32),
                         indexing='xy')

    # å±•å¹³
    u_flat = u.flatten()  # [H*W]
    v_flat = v.flatten()  # [H*W]
    depth_flat = depth.reshape(B, -1)  # [B, H*W]

    points_list = []

    for b in range(B):
        # å½“å‰æ‰¹æ¬¡çš„å†…å‚
        if intrinsics is None:
            # ä½¿ç”¨é»˜è®¤å†…å‚ï¼ˆå‡è®¾æ ‡å‡†åŒ–åæ ‡ï¼‰
            fx = fy = min(H, W) / 2.0
            cx, cy = W / 2.0, H / 2.0
        else:
            fx = intrinsics[b, 0, 0].item()
            fy = intrinsics[b, 1, 1].item()
            cx = intrinsics[b, 0, 2].item()
            cy = intrinsics[b, 1, 2].item()

        d = depth_flat[b]  # [H*W]

        # è¿‡æ»¤æ— æ•ˆæ·±åº¦
        valid_mask = (d > 0) & (d < max_depth) & torch.isfinite(d)

        if valid_mask.sum() == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç‚¹
            points = torch.zeros(1, 3, device=device)
            points_list.append(points)
            continue

        # è·å–æœ‰æ•ˆçš„åƒç´ åæ ‡å’Œæ·±åº¦
        u_valid = u_flat[valid_mask]
        v_valid = v_flat[valid_mask]
        d_valid = d[valid_mask]

        # è®¡ç®—3Dåæ ‡
        x = (u_valid - cx) * d_valid / fx
        y = (v_valid - cy) * d_valid / fy
        z = d_valid

        # ç»„åˆ3Dç‚¹
        points = torch.stack([x, y, z], dim=1)  # [N_valid, 3]
        points_list.append(points)

    return points_list


def pointcloud_to_voxel(pointclouds: List[torch.Tensor],
                       colors: Optional[List[torch.Tensor]] = None,
                       voxel_size: int = 64,
                       spatial_range: Tuple[float, float] = (-2.0, 2.0)) -> torch.Tensor:
    """
    å°†ç‚¹äº‘è½¬æ¢ä¸ºä½“ç´ ç½‘æ ¼

    Args:
        pointclouds: ç‚¹äº‘åˆ—è¡¨ [B x [N_i, 3]]
        colors: é¢œè‰²åˆ—è¡¨ [B x [N_i, 3]] (å¯é€‰)
        voxel_size: ä½“ç´ ç½‘æ ¼å¤§å°
        spatial_range: ç©ºé—´èŒƒå›´ (min, max)

    Returns:
        voxels: ä½“ç´ ç½‘æ ¼ [B, C, D, H, W]
    """
    B = len(pointclouds)
    device = pointclouds[0].device if pointclouds and len(pointclouds[0]) > 0 else torch.device('cpu')

    # ç¡®å®šé€šé“æ•°
    if colors is not None:
        channels = 4  # RGB + density
    else:
        channels = 1  # density only

    voxels = torch.zeros(B, channels, voxel_size, voxel_size, voxel_size, device=device)

    for b in range(B):
        points = pointclouds[b]  # [N, 3]

        if points.shape[0] == 0:
            continue

        # æ ‡å‡†åŒ–åˆ°ä½“ç´ ç½‘æ ¼åæ ‡ [0, voxel_size-1]
        points_norm = (points - spatial_range[0]) / (spatial_range[1] - spatial_range[0])
        points_norm = points_norm * (voxel_size - 1)

        # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
        coords = points_norm.round().long()

        # è¿‡æ»¤è¶…å‡ºèŒƒå›´çš„ç‚¹
        valid_mask = (coords >= 0).all(dim=1) & (coords < voxel_size).all(dim=1)
        coords = coords[valid_mask]

        if coords.shape[0] == 0:
            continue

        # å¡«å……ä½“ç´ 
        x_coords, y_coords, z_coords = coords[:, 0], coords[:, 1], coords[:, 2]

        if colors is not None and b < len(colors):
            point_colors = colors[b][valid_mask]  # [N_valid, 3]

            # å¯†åº¦é€šé“
            voxels[b, 0, x_coords, y_coords, z_coords] = 1.0

            # RGBé€šé“ - å¤„ç†å¤šä¸ªç‚¹æ˜ å°„åˆ°åŒä¸€ä½“ç´ çš„æƒ…å†µ
            for i in range(3):
                # ä½¿ç”¨å¹³å‡å€¼å¤„ç†é‡å 
                voxels[b, i+1].index_put_(
                    (x_coords, y_coords, z_coords),
                    point_colors[:, i],
                    accumulate=True
                )
                # è®¡ç®—æ¯ä¸ªä½“ç´ çš„ç‚¹æ•°é‡è¿›è¡Œå½’ä¸€åŒ–
                count_voxels = torch.zeros_like(voxels[b, 0])
                count_voxels.index_put_(
                    (x_coords, y_coords, z_coords),
                    torch.ones_like(x_coords, dtype=torch.float32),
                    accumulate=True
                )
                # å½’ä¸€åŒ–ï¼ˆé¿å…é™¤é›¶ï¼‰
                mask = count_voxels > 0
                voxels[b, i+1][mask] = voxels[b, i+1][mask] / count_voxels[mask]
        else:
            # ä»…å¯†åº¦
            voxels[b, 0, x_coords, y_coords, z_coords] = 1.0

    return voxels


class DepthToVoxelConverter(nn.Module):
    """
    æ·±åº¦å›¾åˆ°ä½“ç´ çš„è½¬æ¢å™¨
    """

    def __init__(self,
                 voxel_size: int = 64,
                 depth_range: Tuple[float, float] = (0.1, 10.0),
                 spatial_range: Tuple[float, float] = (-2.0, 2.0),
                 use_color: bool = True):
        super(DepthToVoxelConverter, self).__init__()

        self.voxel_size = voxel_size
        self.depth_range = depth_range
        self.spatial_range = spatial_range
        self.use_color = use_color

        # æ³¨å†Œç›¸æœºå†…å‚ï¼ˆå¯é€‰ï¼‰
        self.register_buffer('intrinsics', None)

    def set_intrinsics(self, intrinsics: torch.Tensor):
        """è®¾ç½®ç›¸æœºå†…å‚"""
        self.register_buffer('intrinsics', intrinsics)

    def images_to_voxels(self, rgbd_images: torch.Tensor) -> torch.Tensor:
        """
        å°†RGBDå›¾åƒè½¬æ¢ä¸ºä½“ç´ 

        Args:
            rgbd_images: RGBDå›¾åƒ [B, 4, H, W] (RGB + Depth)

        Returns:
            voxels: ä½“ç´ ç½‘æ ¼ [B, C, D, H, W]
        """
        B, C, H, W = rgbd_images.shape
        device = rgbd_images.device

        if C != 4:
            raise ValueError(f"æœŸæœ›4é€šé“RGBDå›¾åƒï¼Œä½†å¾—åˆ°{C}é€šé“")

        # åˆ†ç¦»RGBå’Œæ·±åº¦
        rgb_images = rgbd_images[:, :3]  # [B, 3, H, W]
        depth_images = rgbd_images[:, 3:4]  # [B, 1, H, W]

        # è½¬æ¢ä¸ºç‚¹äº‘
        pointclouds = depth_to_pointcloud(
            depth_images,
            self.intrinsics,
            max_depth=self.depth_range[1]
        )

        # æå–å¯¹åº”çš„é¢œè‰²
        colors = None
        if self.use_color:
            colors = []
            for b in range(B):
                # è·å–æœ‰æ•ˆæ·±åº¦çš„åƒç´ åæ ‡
                depth_b = depth_images[b, 0]  # [H, W]
                rgb_b = rgb_images[b]  # [3, H, W]

                # åˆ›å»ºåæ ‡ç½‘æ ¼
                u, v = torch.meshgrid(torch.arange(W, device=device, dtype=torch.float32),
                                     torch.arange(H, device=device, dtype=torch.float32),
                                     indexing='xy')

                # å±•å¹³å¹¶è¿‡æ»¤æœ‰æ•ˆæ·±åº¦
                u_flat = u.flatten()
                v_flat = v.flatten()
                depth_flat = depth_b.flatten()

                valid_mask = (depth_flat > 0) & (depth_flat < self.depth_range[1]) & torch.isfinite(depth_flat)

                if valid_mask.sum() > 0:
                    u_valid = u_flat[valid_mask].long()
                    v_valid = v_flat[valid_mask].long()

                    # ç¡®ä¿åæ ‡åœ¨èŒƒå›´å†…
                    u_valid = torch.clamp(u_valid, 0, W-1)
                    v_valid = torch.clamp(v_valid, 0, H-1)

                    # æå–å¯¹åº”ä½ç½®çš„RGBå€¼
                    rgb_values = rgb_b[:, v_valid, u_valid].t()  # [N_valid, 3]
                    colors.append(rgb_values)
                else:
                    colors.append(torch.zeros(1, 3, device=device))

        # è½¬æ¢ä¸ºä½“ç´ 
        voxels = pointcloud_to_voxel(
            pointclouds,
            colors,
            self.voxel_size,
            self.spatial_range
        )

        return voxels

    def depth_to_voxel(self, depth_images: torch.Tensor) -> torch.Tensor:
        """
        ä»…ä»æ·±åº¦å›¾ç”Ÿæˆä½“ç´ ï¼ˆæ— é¢œè‰²ä¿¡æ¯ï¼‰

        Args:
            depth_images: æ·±åº¦å›¾ [B, 1, H, W]

        Returns:
            voxels: ä½“ç´ ç½‘æ ¼ [B, 1, D, H, W]
        """
        # è½¬æ¢ä¸ºç‚¹äº‘
        pointclouds = depth_to_pointcloud(
            depth_images,
            self.intrinsics,
            max_depth=self.depth_range[1]
        )

        # è½¬æ¢ä¸ºä½“ç´ ï¼ˆæ— é¢œè‰²ï¼‰
        voxels = pointcloud_to_voxel(
            pointclouds,
            colors=None,
            voxel_size=self.voxel_size,
            spatial_range=self.spatial_range
        )

        return voxels


def voxel_grid_sampling(voxels: torch.Tensor,
                       target_size: int,
                       mode: str = 'trilinear') -> torch.Tensor:
    """
    ä½“ç´ ç½‘æ ¼é‡é‡‡æ ·

    Args:
        voxels: è¾“å…¥ä½“ç´  [B, C, D, H, W]
        target_size: ç›®æ ‡å°ºå¯¸
        mode: æ’å€¼æ¨¡å¼

    Returns:
        resampled_voxels: é‡é‡‡æ ·ä½“ç´  [B, C, target_size, target_size, target_size]
    """
    return F.interpolate(voxels, size=(target_size, target_size, target_size),
                        mode=mode, align_corners=False)


def voxel_to_mesh(voxels: torch.Tensor, threshold: float = 0.5):
    """
    å°†ä½“ç´ è½¬æ¢ä¸ºç½‘æ ¼ï¼ˆä½¿ç”¨marching cubesç®—æ³•ï¼‰
    æ³¨æ„ï¼šè¿™éœ€è¦é¢å¤–çš„åº“å¦‚scikit-image

    Args:
        voxels: ä½“ç´ æ•°æ® [D, H, W]
        threshold: ç­‰å€¼é¢é˜ˆå€¼

    Returns:
        vertices, faces: ç½‘æ ¼é¡¶ç‚¹å’Œé¢
    """
    try:
        from skimage import measure

        # è½¬æ¢ä¸ºnumpy
        voxel_np = voxels.cpu().numpy()

        # Marching cubes
        vertices, faces, _, _ = measure.marching_cubes(voxel_np, threshold)

        return vertices, faces
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… scikit-image æ¥ä½¿ç”¨ç½‘æ ¼è½¬æ¢åŠŸèƒ½")


def create_multiscale_voxels(rgbd_images: torch.Tensor,
                            scales: List[int] = [16, 32, 64],
                            depth_range: Tuple[float, float] = (0.1, 10.0)) -> Dict[int, torch.Tensor]:
    """
    åˆ›å»ºå¤šå°ºåº¦ä½“ç´ è¡¨ç¤º

    Args:
        rgbd_images: RGBDå›¾åƒ [B, 4, H, W]
        scales: ä½“ç´ å°ºåº¦åˆ—è¡¨
        depth_range: æ·±åº¦èŒƒå›´

    Returns:
        multiscale_voxels: å¤šå°ºåº¦ä½“ç´ å­—å…¸ {scale: voxels}
    """
    multiscale_voxels = {}

    for scale in scales:
        converter = DepthToVoxelConverter(
            voxel_size=scale,
            depth_range=depth_range,
            use_color=True
        )

        voxels = converter.images_to_voxels(rgbd_images)
        multiscale_voxels[scale] = voxels

    return multiscale_voxels


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
def test_voxel_conversion():
    """æµ‹è¯•ä½“ç´ è½¬æ¢åŠŸèƒ½"""
    print("=== æµ‹è¯•ä½“ç´ è½¬æ¢å·¥å…· ===")

    try:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
        print("\n1. åˆ›å»ºæµ‹è¯•æ•°æ®")
        batch_size = 2
        H, W = 128, 128

        # åˆ›å»ºRGBDå›¾åƒ
        rgb_images = torch.randn(batch_size, 3, H, W, device=device)

        # åˆ›å»ºåˆæˆæ·±åº¦å›¾ï¼ˆä¸­å¿ƒè¿‘ï¼Œè¾¹ç¼˜è¿œï¼‰
        y, x = torch.meshgrid(torch.linspace(-1, 1, H), torch.linspace(-1, 1, W), indexing='ij')
        depth_pattern = torch.exp(-(x**2 + y**2))  # é«˜æ–¯åˆ†å¸ƒ
        depth_images = depth_pattern.unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        depth_images = depth_images.to(device) * 5.0 + 1.0  # èŒƒå›´ [1, 6]

        rgbd_images = torch.cat([rgb_images, depth_images], dim=1)

        print(f"âœ… RGBDå›¾åƒå½¢çŠ¶: {rgbd_images.shape}")
        print(f"   æ·±åº¦èŒƒå›´: {depth_images.min():.3f} - {depth_images.max():.3f}")

        # 2. æµ‹è¯•å•å°ºåº¦è½¬æ¢
        print("\n2. æµ‹è¯•å•å°ºåº¦ä½“ç´ è½¬æ¢")
        converter = DepthToVoxelConverter(
            voxel_size=64,
            depth_range=(0.5, 10.0),
            use_color=True
        )

        voxels = converter.images_to_voxels(rgbd_images)
        print(f"âœ… ä½“ç´ å½¢çŠ¶: {voxels.shape}")
        print(f"   ä½“ç´ å ç”¨ç‡: {(voxels[:, 0] > 0).float().mean():.3f}")

        # 3. æµ‹è¯•å¤šå°ºåº¦è½¬æ¢
        print("\n3. æµ‹è¯•å¤šå°ºåº¦ä½“ç´ è½¬æ¢")
        multiscale_voxels = create_multiscale_voxels(rgbd_images, scales=[16, 32, 64])

        for scale, voxels_scale in multiscale_voxels.items():
            occupancy = (voxels_scale[:, 0] > 0).float().mean()
            print(f"âœ… å°ºåº¦ {scale}: {voxels_scale.shape}, å ç”¨ç‡: {occupancy:.3f}")

        # 4. æµ‹è¯•ä½“ç´ é‡é‡‡æ ·
        print("\n4. æµ‹è¯•ä½“ç´ é‡é‡‡æ ·")
        original_voxels = multiscale_voxels[64]
        resampled_voxels = voxel_grid_sampling(original_voxels, target_size=32)
        print(f"âœ… é‡é‡‡æ ·: {original_voxels.shape} -> {resampled_voxels.shape}")

        # 5. æµ‹è¯•ä»…æ·±åº¦è½¬æ¢
        print("\n5. æµ‹è¯•ä»…æ·±åº¦ä½“ç´ è½¬æ¢")
        depth_only_voxels = converter.depth_to_voxel(depth_images)
        print(f"âœ… æ·±åº¦ä½“ç´ å½¢çŠ¶: {depth_only_voxels.shape}")

        print("\nğŸ‰ ä½“ç´ è½¬æ¢æµ‹è¯•å®Œæˆ!")

        return multiscale_voxels

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    test_voxel_conversion()