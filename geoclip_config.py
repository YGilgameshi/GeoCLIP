"""
GeoCLIP Configuration File
ç®¡ç†æ•°æ®é›†è·¯å¾„å’Œå…¨å±€é…ç½®
"""

import os
from pathlib import Path

# ================================
# å…¨å±€æ•°æ®é›†é…ç½®
# ================================

# æ•°æ®é›†æ ¹ç›®å½• - è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹
DATA_ROOT = './geoclip/datasets'  # é»˜è®¤AdaCLIPæ•°æ®é›†è·¯å¾„

# å¦‚æœç¯å¢ƒå˜é‡ä¸­å®šä¹‰äº†æ•°æ®é›†æ ¹ç›®å½•ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
if 'GEOCLIP_DATA_ROOT' in os.environ:
    DATA_ROOT = os.environ['GEOCLIP_DATA_ROOT']

# ç¡®ä¿æ•°æ®é›†è·¯å¾„å­˜åœ¨
DATA_ROOT = Path(DATA_ROOT).absolute()
if not DATA_ROOT.exists():
    print(f"è­¦å‘Š: æ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {DATA_ROOT}")
    print("è¯·è®¾ç½®æ­£ç¡®çš„DATA_ROOTè·¯å¾„æˆ–è®¾ç½®ç¯å¢ƒå˜é‡GEOCLIP_DATA_ROOT")

# ================================
# å„ä¸ªæ•°æ®é›†çš„å…·ä½“è·¯å¾„
# ================================

# å·¥ä¸šå¼‚å¸¸æ£€æµ‹æ•°æ®é›†
MVTEC_ROOT = DATA_ROOT / 'MVTec_AD'
VISA_ROOT = DATA_ROOT / 'VisA'
BTAD_ROOT = DATA_ROOT / 'BTAD'
MPDD_ROOT = DATA_ROOT / 'MPDD'
SDD_ROOT = DATA_ROOT / 'SDD_anomaly_detection'

# åŒ»å­¦å¼‚å¸¸æ£€æµ‹æ•°æ®é›†
COLONDB_ROOT = DATA_ROOT / 'CVC-ColonDB'
CLINICDB_ROOT = DATA_ROOT / 'CVC-ClinicDB'
ISIC_ROOT = DATA_ROOT / 'ISIC2018'
BRAIN_MRI_ROOT = DATA_ROOT / 'brain_mri'
HEAD_CT_ROOT = DATA_ROOT / 'head_ct'

# å…¶ä»–æ•°æ®é›†
DTD_ROOT = DATA_ROOT / 'dtd'
DAGM_ROOT = DATA_ROOT / 'DAGM'
BR35H_ROOT = DATA_ROOT / 'br35h'
TN3K_ROOT = DATA_ROOT / 'TN3K'

# ================================
# æ•°æ®é›†ç±»åˆ«å®šä¹‰
# ================================

# MVTec AD ç±»åˆ«
MVTEC_CLS_NAMES = [
    'bottle', 'cable', 'capsule', 'carpet', 'grid',
    'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',
    'tile', 'toothbrush', 'transistor', 'wood', 'zipper'
]

# VisA ç±»åˆ«
VISA_CLS_NAMES = [
    'candle', 'capsules', 'cashew', 'chewinggum', 'fryum',
    'macaroni1', 'macaroni2', 'pcb1', 'pcb2', 'pcb3',
    'pcb4', 'pipe_fryum'
]

# BTAD ç±»åˆ«
BTAD_CLS_NAMES = ['01', '02', '03']

# åŒ»å­¦æ•°æ®é›†ç±»åˆ«
COLONDB_CLS_NAMES = ['ColonDB']
CLINICDB_CLS_NAMES = ['ClinicDB']

# ================================
# GeoCLIPç‰¹å®šé…ç½®
# ================================

# æ·±åº¦ç¼“å­˜é…ç½®
DEPTH_CACHE_ROOT = Path('./depth_cache')
DEPTH_CACHE_ROOT.mkdir(exist_ok=True)

# é»˜è®¤æ·±åº¦ä¼°è®¡å™¨é…ç½®
DEFAULT_DEPTH_CONFIG = {
    'model_type': 'DPT_Large',
    'device': 'cuda',
    'input_size': (384, 384)
}

# é»˜è®¤ä½“ç´ è½¬æ¢é…ç½®
DEFAULT_VOXEL_CONFIG = {
    'voxel_size': 64,
    'depth_range': (0.1, 10.0),
    'spatial_range': (-2.0, 2.0),
    'use_color': True
}

# é»˜è®¤å‡ ä½•ç¼–ç å™¨é…ç½®
DEFAULT_GEOMETRY_CONFIG = {
    'type': 'voxel',
    'in_channels': 4,  # RGB + Depth
    'base_channels': 64,
    'num_stages': 4,
    'output_channels': 512,
    'voxel_size': 64
}

# ================================
# è®­ç»ƒé…ç½®é¢„è®¾
# ================================

# å¿«é€Ÿè®­ç»ƒé…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
QUICK_TRAIN_CONFIG = {
    'epoch': 10,
    'batch_size': 4,
    'learning_rate': 1e-3,
    'print_freq': 2,
    'save_freq': 5,
    'preprocess_depth': False
}

# æ ‡å‡†è®­ç»ƒé…ç½®
STANDARD_TRAIN_CONFIG = {
    'epoch': 100,
    'batch_size': 8,
    'learning_rate': 1e-4,
    'print_freq': 10,
    'save_freq': 5,
    'preprocess_depth': True
}

# é«˜è´¨é‡è®­ç»ƒé…ç½®
HIGH_QUALITY_TRAIN_CONFIG = {
    'epoch': 200,
    'batch_size': 16,
    'learning_rate': 5e-5,
    'print_freq': 5,
    'save_freq': 10,
    'preprocess_depth': True
}

# ================================
# æ•°æ®é›†ç»„åˆé¢„è®¾
# ================================

# AdaCLIPåŸå§‹ç»„åˆ
ADACLIP_TRAIN_COMBO_1 = {
    'training_data': ['mvtec', 'colondb'],
    'testing_data': ['visa']
}

ADACLIP_TRAIN_COMBO_2 = {
    'training_data': ['visa', 'clinicdb'],
    'testing_data': ['mvtec']
}

# GeoCLIPæ¨èç»„åˆ
GEOCLIP_INDUSTRIAL_COMBO = {
    'training_data': ['mvtec', 'visa'],
    'testing_data': ['btad']
}

GEOCLIP_MEDICAL_COMBO = {
    'training_data': ['colondb', 'clinicdb'],
    'testing_data': ['isic']
}

GEOCLIP_MIXED_COMBO = {
    'training_data': ['mvtec', 'colondb', 'visa'],
    'testing_data': ['btad', 'clinicdb']
}

# ================================
# æ¨¡å‹é…ç½®é¢„è®¾
# ================================

# è½»é‡çº§é…ç½®
LIGHT_MODEL_CONFIG = {
    'model': 'ViT-B-16',
    'geometry_encoder': 'voxel',
    'fusion_type': 'simple_concat',
    'fusion_dim': 512,
    'freeze_clip': False
}

# æ ‡å‡†é…ç½®
STANDARD_MODEL_CONFIG = {
    'model': 'ViT-L-14',
    'geometry_encoder': 'voxel',
    'fusion_type': 'cross_attention',
    'fusion_dim': 1024,
    'freeze_clip': False
}

# é«˜ç«¯é…ç½®
PREMIUM_MODEL_CONFIG = {
    'model': 'ViT-L-14-336',
    'geometry_encoder': 'hierarchical',
    'fusion_type': 'cross_attention',
    'fusion_dim': 1024,
    'freeze_clip': False
}


# ================================
# å®ç”¨å‡½æ•°
# ================================

def get_dataset_info(dataset_name: str) -> dict:
    """è·å–æ•°æ®é›†ä¿¡æ¯"""
    dataset_info_map = {
        'mvtec': {
            'root': MVTEC_ROOT,
            'classes': MVTEC_CLS_NAMES,
            'type': 'industrial',
            'description': 'MVTec AD - Industrial Anomaly Detection'
        },
        'visa': {
            'root': VISA_ROOT,
            'classes': VISA_CLS_NAMES,
            'type': 'industrial',
            'description': 'VisA - Visual Anomaly Detection'
        },
        'btad': {
            'root': BTAD_ROOT,
            'classes': BTAD_CLS_NAMES,
            'type': 'industrial',
            'description': 'BTAD - Beantech Anomaly Detection'
        },
        'colondb': {
            'root': COLONDB_ROOT,
            'classes': COLONDB_CLS_NAMES,
            'type': 'medical',
            'description': 'CVC-ColonDB - Colon Polyp Detection'
        },
        'clinicdb': {
            'root': CLINICDB_ROOT,
            'classes': CLINICDB_CLS_NAMES,
            'type': 'medical',
            'description': 'CVC-ClinicDB - Clinical Polyp Detection'
        }
    }

    return dataset_info_map.get(dataset_name, {})


def check_dataset_availability():
    """æ£€æŸ¥æ•°æ®é›†å¯ç”¨æ€§"""
    print("ğŸ” æ£€æŸ¥æ•°æ®é›†å¯ç”¨æ€§...")
    print(f"æ•°æ®é›†æ ¹ç›®å½•: {DATA_ROOT}")

    datasets = {
        'mvtec': MVTEC_ROOT,
        'visa': VISA_ROOT,
        'btad': BTAD_ROOT,
        'colondb': COLONDB_ROOT,
        'clinicdb': CLINICDB_ROOT,
    }

    available = []
    missing = []

    for name, path in datasets.items():
        if path.exists():
            available.append(name)
            print(f"âœ… {name}: {path}")
        else:
            missing.append(name)
            print(f"âŒ {name}: {path} (ä¸å­˜åœ¨)")

    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"âœ… å¯ç”¨æ•°æ®é›†: {len(available)} ({', '.join(available)})")
    print(f"âŒ ç¼ºå¤±æ•°æ®é›†: {len(missing)} ({', '.join(missing)})")

    if missing:
        print(f"\nğŸ’¡ ä¸‹è½½ç¼ºå¤±çš„æ•°æ®é›†:")
        for name in missing:
            info = get_dataset_info(name)
            if info:
                print(f"   {name}: {info['description']}")

    return available, missing


def get_recommended_config(scenario: str = 'standard') -> dict:
    """è·å–æ¨èçš„è®­ç»ƒé…ç½®"""
    if scenario == 'debug':
        return {
            **QUICK_TRAIN_CONFIG,
            **LIGHT_MODEL_CONFIG,
            **ADACLIP_TRAIN_COMBO_1
        }
    elif scenario == 'standard':
        return {
            **STANDARD_TRAIN_CONFIG,
            **STANDARD_MODEL_CONFIG,
            **ADACLIP_TRAIN_COMBO_1
        }
    elif scenario == 'high_quality':
        return {
            **HIGH_QUALITY_TRAIN_CONFIG,
            **PREMIUM_MODEL_CONFIG,
            **GEOCLIP_MIXED_COMBO
        }
    elif scenario == 'industrial':
        return {
            **STANDARD_TRAIN_CONFIG,
            **STANDARD_MODEL_CONFIG,
            **GEOCLIP_INDUSTRIAL_COMBO
        }
    elif scenario == 'medical':
        return {
            **STANDARD_TRAIN_CONFIG,
            **STANDARD_MODEL_CONFIG,
            **GEOCLIP_MEDICAL_COMBO
        }
    else:
        raise ValueError(f"æœªçŸ¥åœºæ™¯: {scenario}")


def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡å’Œè·¯å¾„"""
    # è®¾ç½®CUDAç›¸å…³ç¯å¢ƒå˜é‡
    os.environ.setdefault('CUBLAS_WORKSPACE_CONFIG', ':4096:8')

    # æ·»åŠ å½“å‰é¡¹ç›®åˆ°Pythonè·¯å¾„
    current_dir = Path(__file__).parent.absolute()
    if str(current_dir) not in os.sys.path:
        os.sys.path.insert(0, str(current_dir))

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    DEPTH_CACHE_ROOT.mkdir(exist_ok=True)

    print("ğŸ”§ ç¯å¢ƒè®¾ç½®å®Œæˆ")
    print(f"   é¡¹ç›®è·¯å¾„: {current_dir}")
    print(f"   æ•°æ®æ ¹ç›®å½•: {DATA_ROOT}")
    print(f"   æ·±åº¦ç¼“å­˜ç›®å½•: {DEPTH_CACHE_ROOT}")


def print_config_summary():
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("\nğŸ“‹ GeoCLIPé…ç½®æ‘˜è¦")
    print("=" * 40)
    print(f"æ•°æ®æ ¹ç›®å½•: {DATA_ROOT}")
    print(f"æ·±åº¦ç¼“å­˜ç›®å½•: {DEPTH_CACHE_ROOT}")

    print(f"\næ”¯æŒçš„æ•°æ®é›†:")
    for name in ['mvtec', 'visa', 'btad', 'colondb', 'clinicdb']:
        info = get_dataset_info(name)
        status = "âœ…" if info['root'].exists() else "âŒ"
        print(f"  {status} {name}: {info['description']}")

    print(f"\né¢„è®¾é…ç½®:")
    scenarios = ['debug', 'standard', 'high_quality', 'industrial', 'medical']
    for scenario in scenarios:
        try:
            config = get_recommended_config(scenario)
            print(f"  ğŸ“‹ {scenario}: {config.get('model', 'N/A')} + {'/'.join(config.get('training_data', []))}")
        except:
            print(f"  âŒ {scenario}: é…ç½®é”™è¯¯")


# ================================
# å¿«é€Ÿå¯åŠ¨å‡½æ•°
# ================================

def quick_start_debug():
    """å¿«é€Ÿå¼€å§‹è°ƒè¯•æ¨¡å¼è®­ç»ƒ"""
    config = get_recommended_config('debug')
    print("ğŸš€ å¿«é€Ÿå¯åŠ¨ - è°ƒè¯•æ¨¡å¼")
    print(f"é…ç½®: {config}")
    return config


def quick_start_standard():
    """å¿«é€Ÿå¼€å§‹æ ‡å‡†è®­ç»ƒ"""
    config = get_recommended_config('standard')
    print("ğŸš€ å¿«é€Ÿå¯åŠ¨ - æ ‡å‡†æ¨¡å¼")
    print(f"é…ç½®: {config}")
    return config


# ================================
# è‡ªåŠ¨æ£€æµ‹å’Œå»ºè®®
# ================================

def auto_detect_best_config():
    """è‡ªåŠ¨æ£€æµ‹æœ€ä½³é…ç½®"""
    available_datasets, missing_datasets = check_dataset_availability()

    # æ ¹æ®å¯ç”¨æ•°æ®é›†æ¨èé…ç½®
    if len(available_datasets) >= 3:
        return get_recommended_config('high_quality')
    elif 'mvtec' in available_datasets and 'colondb' in available_datasets:
        return get_recommended_config('standard')
    elif len(available_datasets) >= 1:
        return get_recommended_config('debug')
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®é›†")
        return None


# ä¸»å‡½æ•°ï¼šå¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œé…ç½®æ£€æŸ¥
if __name__ == "__main__":
    print("ğŸ”§ GeoCLIPé…ç½®æ£€æŸ¥")
    print("=" * 50)

    # è®¾ç½®ç¯å¢ƒ
    setup_environment()

    # æ£€æŸ¥æ•°æ®é›†
    check_dataset_availability()

    # æ‰“å°é…ç½®æ‘˜è¦
    print_config_summary()

    # æ¨èæœ€ä½³é…ç½®
    print("\nğŸ’¡ æ¨èé…ç½®:")
    best_config = auto_detect_best_config()
    if best_config:
        print("æ ¹æ®æ‚¨çš„æ•°æ®é›†æƒ…å†µï¼Œæ¨èä½¿ç”¨ä»¥ä¸‹é…ç½®å¼€å§‹è®­ç»ƒ:")
        print(f"python train_geoclip.py \\")
        print(f"  --training_data {' '.join(best_config['training_data'])} \\")
        print(f"  --testing_data {' '.join(best_config['testing_data'])} \\")
        print(f"  --model {best_config['model']} \\")
        print(f"  --epoch {best_config['epoch']} \\")
        print(f"  --batch_size {best_config['batch_size']} \\")
        print(f"  --learning_rate {best_config['learning_rate']}")

    print("\nâœ… é…ç½®æ£€æŸ¥å®Œæˆï¼")