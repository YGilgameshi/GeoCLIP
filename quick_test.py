
"""
GeoCLIP å¿«é€ŸåŠŸèƒ½æµ‹è¯•
ä½¿ç”¨æœ€å°é…ç½®å¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

import torch
import torch.nn as nn
import numpy as np
import time


def quick_test():
    """å¿«é€Ÿæµ‹è¯•GeoCLIPæ ¸å¿ƒåŠŸèƒ½"""
    print("âš¡ GeoCLIP å¿«é€ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 40)

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸ è®¾å¤‡: {device}")

    # æµ‹è¯•1: èåˆæ¨¡å—
    print("\n1ï¸âƒ£ æµ‹è¯•ç‰¹å¾èåˆæ¨¡å—...")
    try:
        from geoclip.models.fusion_module import create_fusion_module

        fusion_config = {
            'type': 'simple_concat',
            'clip_dim': 256,
            'geometry_dim': 256,
            'output_dim': 256
        }

        fusion_module = create_fusion_module(fusion_config).to(device)

        # æµ‹è¯•æ•°æ®
        clip_feat = torch.randn(2, 256, device=device)
        geometry_feat = torch.randn(2, 256, device=device)

        with torch.no_grad():
            output = fusion_module(clip_feat, geometry_feat)

        print(f"âœ… èåˆæ¨¡å—: {clip_feat.shape} + {geometry_feat.shape} -> {output.shape}")

    except Exception as e:
        print(f"âŒ èåˆæ¨¡å—å¤±è´¥: {e}")
        return False

    # æµ‹è¯•2: ä½“ç´ è½¬æ¢
    print("\n2ï¸âƒ£ æµ‹è¯•ä½“ç´ è½¬æ¢...")
    try:
        from geoclip.utils.voxel_utils import DepthToVoxelConverter

        converter = DepthToVoxelConverter(voxel_size=16, use_color=True)

        # åˆ›å»ºRGBDæµ‹è¯•æ•°æ®
        rgbd = torch.randn(2, 4, 64, 64, device=device)  # å°å°ºå¯¸å¿«é€Ÿæµ‹è¯•

        with torch.no_grad():
            voxels = converter.images_to_voxels(rgbd)

        print(f"âœ… ä½“ç´ è½¬æ¢: {rgbd.shape} -> {voxels.shape}")

    except Exception as e:
        print(f"âŒ ä½“ç´ è½¬æ¢å¤±è´¥: {e}")
        return False

    # æµ‹è¯•3: å‡ ä½•ç¼–ç å™¨
    print("\n3ï¸âƒ£ æµ‹è¯•å‡ ä½•ç¼–ç å™¨...")
    try:
        from geoclip.models.geometry_encoder import create_geometry_encoder

        config = {
            'type': 'voxel',
            'in_channels': 4,
            'base_channels': 16,  # å°é€šé“æ•°å¿«é€Ÿæµ‹è¯•
            'num_stages': 2,
            'output_channels': 128,
            'voxel_size': 16
        }

        encoder = create_geometry_encoder(config).to(device)

        # ä½¿ç”¨ä¹‹å‰çš„ä½“ç´ æ•°æ®
        with torch.no_grad():
            features = encoder(voxels)

        print(f"âœ… å‡ ä½•ç¼–ç : {voxels.shape} -> {features.shape}")

    except Exception as e:
        print(f"âŒ å‡ ä½•ç¼–ç å¤±è´¥: {e}")
        return False

    # æµ‹è¯•4: æŒ‡æ ‡è®¡ç®—
    print("\n4ï¸âƒ£ æµ‹è¯•æŒ‡æ ‡è®¡ç®—...")
    try:
        from geoclip.utils.metrics import AnomalyMetrics

        metrics = AnomalyMetrics()

        # æ¨¡æ‹Ÿé¢„æµ‹å’Œæ ‡ç­¾
        pred = np.random.rand(50)
        labels = np.random.randint(0, 2, 50)

        result = metrics.compute_metrics(pred, labels)

        print(f"âœ… æŒ‡æ ‡è®¡ç®—: AUC={result.get('auc', 0):.3f}, F1={result.get('f1', 0):.3f}")

    except Exception as e:
        print(f"âŒ æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return False

    # æµ‹è¯•5: å¯è§†åŒ–
    print("\n5ï¸âƒ£ æµ‹è¯•å¯è§†åŒ–...")
    try:
        from geoclip.utils.visualization import Visualizer

        viz = Visualizer(save_dir='geoclip/quick_test_viz')

        # åˆ›å»ºç®€å•æµ‹è¯•å›¾
        test_img = np.random.rand(64, 64, 3)
        test_depth = np.random.rand(64, 64)

        viz.plot_depth_visualization(test_img, test_depth, 'quick_test_depth.png')

        print(f"âœ… å¯è§†åŒ–: å›¾ç‰‡ä¿å­˜åˆ° {viz.save_dir}")

    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        return False

    # æµ‹è¯•6: æŸå¤±å‡½æ•°
    print("\n6ï¸âƒ£ æµ‹è¯•æŸå¤±å‡½æ•°...")
    try:
        from geoclip.training.losses import create_loss_function

        loss_config = {
            'type': 'geoclip',
            'contrastive_weight': 1.0,
            'geometry_weight': 0.5,
            'anomaly_weight': 2.0,
            'anomaly_config': {
                'loss_type': 'mse'  # ä½¿ç”¨MSEæŸå¤±é¿å…åˆ†ç±»é—®é¢˜
            }
        }

        loss_fn = create_loss_function(loss_config)

        # æ¨¡æ‹Ÿæ¨¡å‹è¾“å‡ºå’Œç›®æ ‡ - ç¡®ä¿ç»´åº¦åŒ¹é…
        clip_dim = 256
        geometry_dim = 128  # ä¸åŒç»´åº¦æµ‹è¯•è‡ªåŠ¨åŒ¹é…åŠŸèƒ½

        model_outputs = {
            'anomaly_predictions': torch.randn(2, 1, device=device).sigmoid(),
            'clip_features': torch.randn(2, clip_dim, device=device),
            'geometry_features': torch.randn(2, geometry_dim, device=device),
            'depth_maps': torch.rand(2, 1, 32, 32, device=device)
        }

        targets = {
            'anomaly_labels': torch.randint(0, 2, (2,), device=device).float(),  # è½¬ä¸ºfloatç”¨äºå›å½’
            'class_labels': torch.randint(0, 2, (2,), device=device)  # äºŒåˆ†ç±»
        }

        with torch.no_grad():
            loss_dict = loss_fn(model_outputs, targets)

        print(f"âœ… æŸå¤±å‡½æ•°: total_loss={loss_dict['total_loss']:.3f}")
        print(f"   anomaly_loss={loss_dict.get('anomaly_loss', 0):.3f}")
        print(f"   contrastive_loss={loss_dict.get('contrastive_loss', 0):.3f}")
        print(f"   geometry_loss={loss_dict.get('geometry_loss', 0):.3f}")

    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°å¤±è´¥: {e}")
        return False

    # æµ‹è¯•7: ç«¯åˆ°ç«¯æµç¨‹
    print("\n7ï¸âƒ£ æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹...")
    try:
        # åˆ›å»ºç®€åŒ–çš„ç«¯åˆ°ç«¯æµ‹è¯•
        batch_size = 2

        # 1. æ¨¡æ‹Ÿå›¾åƒ
        images = torch.randn(batch_size, 3, 128, 128, device=device)

        # 2. æ¨¡æ‹Ÿæ·±åº¦ (è·³è¿‡å®é™…æ·±åº¦ä¼°è®¡ä»¥åŠ é€Ÿ)
        depths = torch.rand(batch_size, 1, 128, 128, device=device)

        # 3. ä½“ç´ è½¬æ¢
        rgbd = torch.cat([images, depths], dim=1)
        voxels = converter.images_to_voxels(rgbd)

        # 4. ç‰¹å¾æå–
        geometry_feat = encoder(voxels)
        clip_feat = torch.randn(batch_size, 256, device=device)  # æ¨¡æ‹ŸCLIPç‰¹å¾

        # 5. ç‰¹å¾èåˆ
        fusion_config_e2e = {
            'type': 'simple_concat',
            'clip_dim': 256,
            'geometry_dim': geometry_feat.shape[1],
            'output_dim': 256
        }
        fusion_e2e = create_fusion_module(fusion_config_e2e).to(device)
        fused_feat = fusion_e2e(clip_feat, geometry_feat)

        # 6. å¼‚å¸¸æ£€æµ‹
        anomaly_head = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        ).to(device)

        anomaly_scores = anomaly_head(fused_feat)

        print(f"âœ… ç«¯åˆ°ç«¯æµç¨‹:")
        print(f"   å›¾åƒ: {images.shape}")
        print(f"   æ·±åº¦: {depths.shape}")
        print(f"   ä½“ç´ : {voxels.shape}")
        print(f"   èåˆç‰¹å¾: {fused_feat.shape}")
        print(f"   å¼‚å¸¸åˆ†æ•°: {anomaly_scores.shape}")

    except Exception as e:
        print(f"âŒ ç«¯åˆ°ç«¯æµç¨‹å¤±è´¥: {e}")
        return False

    return True


def performance_test():
    """æ€§èƒ½æµ‹è¯•"""
    print("\nâ±ï¸ æ€§èƒ½æµ‹è¯•...")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_sizes = [1, 2, 4] if device == 'cuda' else [1, 2]

    try:
        from geoclip.models.fusion_module import create_fusion_module

        fusion_config = {
            'type': 'cross_attention',
            'clip_dim': 512,
            'geometry_dim': 512,
            'output_dim': 512
        }

        fusion_module = create_fusion_module(fusion_config).to(device)

        print("æ‰¹æ¬¡å¤§å° | å¤„ç†æ—¶é—´(ms) | å†…å­˜ä½¿ç”¨(MB)")
        print("-" * 40)

        for batch_size in batch_sizes:
            clip_feat = torch.randn(batch_size, 512, device=device)
            geometry_feat = torch.randn(batch_size, 512, device=device)

            # é¢„çƒ­
            with torch.no_grad():
                _ = fusion_module(clip_feat, geometry_feat)

            if device == 'cuda':
                torch.cuda.synchronize()
                start_memory = torch.cuda.memory_allocated() / 1024 / 1024

            # æµ‹è¯•æ—¶é—´
            start_time = time.time()

            with torch.no_grad():
                for _ in range(10):  # å¤šæ¬¡è¿è¡Œå–å¹³å‡
                    output = fusion_module(clip_feat, geometry_feat)

            if device == 'cuda':
                torch.cuda.synchronize()

            elapsed_time = (time.time() - start_time) / 10 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            if device == 'cuda':
                end_memory = torch.cuda.memory_allocated() / 1024 / 1024
                memory_used = end_memory - start_memory
            else:
                memory_used = 0

            print(f"{batch_size:8d} | {elapsed_time:10.1f} | {memory_used:10.1f}")

        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")

    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹GeoCLIPå¿«é€Ÿæµ‹è¯•...")

    start_time = time.time()

    # åŠŸèƒ½æµ‹è¯•
    success = quick_test()

    if success:
        print(f"\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡!")

        # æ€§èƒ½æµ‹è¯•
        performance_test()

        total_time = time.time() - start_time
        print(f"\nâ±ï¸ æ€»æµ‹è¯•æ—¶é—´: {total_time:.1f}ç§’")

        print(f"\nâœ… GeoCLIPé¡¹ç›®å·²å‡†å¤‡å°±ç»ª!")
        print(f"ğŸš€ å¯ä»¥è¿è¡Œå®Œæ•´æµ‹è¯•: python end_to_end_test.py")
        print(f"ğŸ“š å¯ä»¥è¿è¡Œä½¿ç”¨ç¤ºä¾‹: python geoclip_usage_example.py")

    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜")
        print(f"ğŸ’¡ å»ºè®®:")
        print(f"   1. è¿è¡Œ python env_check.py æ£€æŸ¥ç¯å¢ƒ")
        print(f"   2. æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…")
        print(f"   3. æ£€æŸ¥import_test.pyçš„ç»“æœ")

    return success


if __name__ == "__main__":
    success = main()